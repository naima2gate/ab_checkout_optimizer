# Checkout Optimizer: A Full-Stack A/B & Bandit Experimentation Framework
This project provides a comprehensive, end-to-end framework for advanced online experimentation. It is designed to move beyond a standard A/B test by integrating powerful statistical methods, including variance reduction, sequential analysis, and causal uplift modeling. The framework is validated by a full simulation pipeline and a comparison with multi-armed bandit policies, ensuring robust and actionable insights for business decisions.

## Problem Statement
- **Hypothesis:** Replacing the "Continue" button with a sticky progress bar in the checkout flow will **increase Gross Profit per Visitor (GPV)**.
- **Primary Metric:** Gross Profit per Visitor (GPV) is defined as (revenue -  discounts - variable costs) per unique visitor - day.
- **Guardrails:** The experiment is monitored to ensure the change does not negatively impact key operational metrics, including Checkout Latency (p95), Refund Rate (%), Support tickets / 1k orders, and 7-day user retention.
- **Exposure Rules:** Users are considered "in experiment" once they reach the /cart page to prevent top-of-funnel dilution.

## Key Features
- **Stratified Experimentation:** Randomizes users into control and treatment groups while maitaining balance across key strata like country, device, and traffic source.
- **Advanced Statistical Analysis:**
    - **CUPED:** Employes CUPED (Controlled-experiment Using Pre-experiment Data) to reduce variance and increase the power of the test.
    - **Sequential Monitoring:** Uses an aplha-spending function (O'Brien-Fleming) for peeking-safe analysis, enabling early stopping and reducing time-to-decision.
    - **Bayesian Analysis:** Provides a probabilistic complement to the frequentist analysis, offering intuitive metrics like P(lift > 0).
- **Causal Uplift Modeling:** Estimates the Conditional Average Treatment Effect (CATE) to identify which user segments respond most favorably to the treatment.
- **Full Simulation Pipeline:** A complete, end-to-end simualtion validates the statistical methods and provides a controlled environment to test different scenarios.
- **Multi-Armed Bandit Comparison:** Simulates and compares the performance of multi-armed bandits algorithms (Thompson Sampling, UCB1, Epsilon-Greedy) against  the traditional A/B test.
- **Interactive Dashboard:** A Streamlit application visualizes key experiment results, making the findings accessible to both technical and non-technical stakeholders.

## Repository layout
The project's code is modular and logically organized, with clear separation between scripts, resusable source code, data, and analysis notebooks.
- ```data/```: Stores all raw and processed data, including the synthetic data and generated by the simulations and final analytical outputs.
- ```notebooks/```: Contains Jupyter notebooks that provide a detailed, step by step walkthrough of the analytical methods and findings.
- ```src/```: Contains the core Python modules and reusable functions that constitute the backend logic of the project.
- ```scripts/```: Holds the main executable scripts that orchestrate the pipeline and act as the entry points for running different stages.
- ```sql/```: Contains SQL files for defining the database schema and performing data quality checks.
- ```README.md```: The main project overview and guide.
- ```requirements.txt```: Lists all python dependencies for a reproducible environment.

## Quickstart

### 1) Install
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Generate synthetic data
```bash
python scripts/generate_data.py --n_users 10000 --days 14 --seed 42
```

### 3) Run A/B Test
```bash
python scripts/run_ab_test.py
```

This will create CSVs under `data/`:
- `assignments.csv`, `sessions.csv`, `events.csv`, `orders.csv`, `perf.csv`, `users.csv`


### 4) Run analysis (CUPED + frequentist + Bayesian + sequential)
```bash
python scripts/run_analysis.py
```

### 5) Launch dashboard
```bash
streamlit run app/streamlit_app.py

```
## Bandits (Multi‑Armed, scalable online allocation)

Run online policies on a continuous user stream with contextual, heterogenous effects:

```bash
python scripts/run_bandits.py --horizon 50000 --n_arms 3 --seed 123
```

Outputs:
- `data/bandits_report.json` — summary of **PCS**, **cumulative regret**, means, and allocation share

Policies included:
- `Thompson (GPV)` — maximizes continuous reward (GPV)
- `Thompson (Conversion)` — maximizes conversion probability
- `UCB1` — exploration via uncertainty bonus
- `Epsilon‑Greedy` — simple baseline


## Key Findings & Results
The experiment and its subsequent analysis provided clear and compelling evidence that the new feature was highly effective. 

### A. A/B Test Analysis
| Condition               | Required Result                    | Actual Result              | Interpretation                                                                 |
|--------------------------|------------------------------------|----------------------------|---------------------------------------------------------------------------------|
| Lift (CUPED-adjusted)    | Positive lift                     | 7.55%                      | The treatment group showed a significant positive increase in GPV compared to the control group. |
| Statistical Significance | P-value < 0.05                    | P-value < 0.001            | The result is highly statistically significant, meaning the observed lift is unlikely due to random chance. |
| Bayesian Probability     | P(lift > 0) > 95%                 | 99.96%                     | Extremely high probability that treatment is better than control. |
| Practical Significance   | P(lift in ROPE) < 1%              | 0.00067%                   | The effect is not practically insignificant. |


### B. Sequential Monitoring
The sequential analysis showed that the experiment could have been stopped early. The data indicates a clear and consistent positive signal that crossed the O'Brien-Fleming stopping boundary on day 8, allowing for a quicker decision than the planned 14-day duration.

### C. Causal Uplift Modeling (Heterogeneity Analysis)
The uplift analysis revealed a wide distribution of treatment effects, indicating that the feature had a different impact on various user segments. This suggests that a targeted rollout could maximize the business impact. The models identified specific user segments, such as mobile users and users from India, as experiencing a substantially higher positive lift.

### D. Multi-Armed Bandit Simulation
The bandit simulation confirmed the A/B test's findings. The policies correctly identified the treatment arm as the best.
Thompson Sampling and UCB1 were highly efficient, achieving the highest cumulative rewards and a 100% Probability of Correct Selection (PCS).
Epsilon-Greedy was the least efficient, as its fixed exploration rate resulted in a lower overall cumulative reward.

This simulation demonstrates that a bandit approach could have been used to dynamically allocate traffic to best performing variant, maximizing returns during the experiment itself.

## Final Recommendation
Based on the compelling evidence from the analysis, the recommendation is a clear GO.

The "Checkout Optimizer" feature successfully proved its value by generating a significant uplift in GPV without harming key guardrail metrics. The analytical framework, including CUPED and sequential monitoring, allowed us to reach this confident conclusion quickly and efficiently.

We recommend moving forward with a full rollout of the feature. For future optimizations, we should use the uplift analysis to identify and target high-response user segments, such as mobile users and users from India, to further maximize the business impact.

## Notes
- Data are **synthetic** with configurable heterogeneity, novelty, drift, and logging loss.
- Intended for education/portfolio.